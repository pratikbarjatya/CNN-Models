{"nbformat":4,"nbformat_minor":0,"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Object Detection using RCNN.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZLiAp5tFOxfJ","colab_type":"text"},"source":["<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"360\" height=\"160\" /></center>"]},{"cell_type":"markdown","metadata":{"id":"LTWdbec7OAyM","colab_type":"text"},"source":["# Object Detection in an Image"]},{"cell_type":"markdown","metadata":{"id":"Vr5tINo0OAyQ","colab_type":"text"},"source":["### Introduction"]},{"cell_type":"markdown","metadata":{"id":"KFLr0m2VOAyT","colab_type":"text"},"source":["So far we have learned different concepts regarding object classification and detection using **Neural Nets**, **ANN**, **CNN**. \n","\n","But certainly this vast field is not only limited till this. Many more advancement has been done in this field in order to do and achieve much more in the **field of Computer Vision**.\n","\n","- An **image classififcation** problem is **predicting the label** of an image among the predefined labels.\n","\n","- It assumes that there is **single object** of interest in the image and it covers a **significant portion** of image.\n","\n","- Detection is not about only **finding the class** of object but also **localizing** the extent of an object in the image.\n","\n","- The object can be **lying anywhere** in the image and can be of **any size(scale)**.\n","\n","<br> \n","<center><img src = \"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od1.png\" ></center>\n","\n","<br> \n","\n","- So object classification is **no more** helpful when:\n","    - **Multiple** objects in image.\n","    - Objects are **small**.\n","    - **Exact** location and size of object in image is desired."]},{"cell_type":"markdown","metadata":{"id":"lg3TonlTOAyW","colab_type":"text"},"source":["Computer Vision is an **interdisciplinary field** that has been **gaining huge amounts of traction** in the recent years(since CNN) and **self driving cars** have taken centre stage.\n","\n","\n","Another integral part of computer vision is **object detection**.\n","\n","- Object Detection aids in **pose estimation**, **vehicle detection**, **surveilence** etc.\n","\n","- The **difference** between object detection algorithms and classification algorithms is that in detection algorithms, we **try to draw a bounding box around the object of interest to locate it wthin the image**.\n","\n","- We might **not** necessarily draw **just one bounding box** in an object detection case, there could be **many bounding boxes** representing **different objects** of interest within the image and we would not know how many beforehand.\n","\n","<br> \n","<center><img src = \"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od2.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"2AO9vnRPOAyY","colab_type":"text"},"source":["<br> \n","\n","<center><img src =\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od3.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"lPeoD9B5OAya","colab_type":"text"},"source":["The **main reason** why we cannot proceed with this problem by **building a standard convolutional network** followed by fully connected layer is:\n","\n","- The **length** of the output layer is variable - **not constant**.\n","\n","- This is because the **number of occurences** of the objects of interest is not fixed."]},{"cell_type":"markdown","metadata":{"id":"F7tjTHxGOAyc","colab_type":"text"},"source":["**An approach**:\n","\n","- To solve this problem it would take **different regions** from the image, and use a CNN to **classify the presence** of the object within that region.\n","\n","<br> \n","\n","**The Problem**:\n","\n","- With this approach, the **objects of interest** might have different **spatial locations** within the image and **different aspect ratios**.\n","\n","- Therefore we would have to **select a huge number of regions** and this could **computationally blow up**.\n","\n","<br> \n","\n","**The Solution**:\n","\n","- Algorithms like **R-CNN**, **Fast R-CNN**, **Faster R-CNN**, **YOLO** etc have been developed to **find these occurences and find them fast**."]},{"cell_type":"markdown","metadata":{"id":"MxwV365bOAyf","colab_type":"text"},"source":["## R-CNN: An Early Application of CNNs to object Detection\n","<br> \n","<center><img src = \"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od4.png\" ></center>"]},{"cell_type":"markdown","metadata":{"id":"tLdTWoazOAyh","colab_type":"text"},"source":["**Region-CNN (R-CNN)** is one of the state-of-the-art **CNN-based deep learning object detection approaches**.\n","\n","- Based on this there are fast **R-CNN** and **faster R-CNN** for faster speed object detection as well as **mask R-CNN** for object instance segmentation.\n","\n","On the other hand, there are also other object detection approaches, such as **YOLO** and **SSD**."]},{"cell_type":"markdown","metadata":{"id":"n2Nbnq0EOAyj","colab_type":"text"},"source":["**To perform object detection, we need to know the class of object and also the bounding box size and location**"]},{"cell_type":"markdown","metadata":{"id":"Wy9vH947OAyl","colab_type":"text"},"source":["Conventionally, for each image, there is **sliding window** to search every position within the image. It is a simple solution.\n","\n","- Differenct objects or even same kind of objects can have **different aspect ratios and sizes** depending on the object size and distance from the camera.\n","\n","- **Different image sizes** also affect the effective window size.\n","\n","- `The process will be extremely slow if we use deep learning CNN for image classification at each location.`\n","\n","<br> \n","<center><img src = \"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od5.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"xV56PlarOAyo","colab_type":"text"},"source":["### Understanding R-CNN"]},{"cell_type":"markdown","metadata":{"id":"TA83VIgqOAyq","colab_type":"text"},"source":["The goal of R-CNN is to take in an image, and correctly identify where the main object (via a bounding box) is in the image.\n","\n","- **Inputs**: Image\n","\n","- **Outputs**: Bounding boxes + labels for each object in the image.\n","\n","<br> \n","<center><img src = \"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od6.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"TW-n87qNOAys","colab_type":"text"},"source":["### What all will be covered?"]},{"cell_type":"markdown","metadata":{"id":"egUO_ZnSOAyt","colab_type":"text"},"source":["1. **Selective Search**\n","\n","2. **CNN-based Classification and Scoring**\n","\n","3. **Results**"]},{"cell_type":"markdown","metadata":{"id":"vsE5dKydOAyv","colab_type":"text"},"source":["### 1. Selective Search"]},{"cell_type":"markdown","metadata":{"id":"3qaO8hN_OAyx","colab_type":"text"},"source":["- **R-CNN** does what we might intuitively do as well - **propose a bunch of boxed in the image oand see if any of them actually correspond to an object**.\n","\n","- It creates these **bounding boxes**, or **region proposals**, using a process called `Selective Search`.\n","\n","    - First, **color similarities**, **texture similaritites**, **region size**, and **region filling** are used as **no-object-based segmentation**.\n","\n","    - Therefore we obtain **many small segmented areas**.\n","\n","    - Then, bottom-up approach is used so that **samll segmented areas are merged together to form larger segmented areas.**\n","\n","    - Thus, **sbout 2K region proposals (bounding box candidates) are generated**.\n","\n","    - At high level, it looks at image through **windows** of *different sizes*, and for each size tries to group together adjacent **pixels** by *texture*, *color*, or *intensity* to identify objects."]},{"cell_type":"markdown","metadata":{"id":"P9N2MbcQOAyz","colab_type":"text"},"source":["<center><img src= \"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od7.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"LVYV-1U5OAy0","colab_type":"text"},"source":["### 2. CNN-based Classification and Scoring"]},{"cell_type":"markdown","metadata":{"id":"Tp9pDR-DOAy4","colab_type":"text"},"source":["<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od8.png\"></center>\n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od9.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"o6YIcHbaOAy6","colab_type":"text"},"source":["**AlexNet is used to extract the CNN features.**"]},{"cell_type":"markdown","metadata":{"id":"885wHDz6OAy7","colab_type":"text"},"source":["**For each proposal, a 4096-dimensional feature vector is computed** by forward propagating a mean-subtracted 227*227 RGB image through five convolutional layers and two fully connected layers."]},{"cell_type":"markdown","metadata":{"id":"ydFchb4COAy9","colab_type":"text"},"source":["The input has the fixed size of 227*227 while bounding boxes have various shapes and sizes.\n","\n","So **all pixels in a tight bounding box are wrapped to 227x227 size**."]},{"cell_type":"markdown","metadata":{"id":"bYo7De0HOAy_","colab_type":"text"},"source":["**The feature vector is scored by SVM** trained for each class."]},{"cell_type":"markdown","metadata":{"id":"c3OJCVOuOAzA","colab_type":"text"},"source":["For each class, **High IoU (Intersection over Union) overlapping bounding boxes are rejected** since they are bounding the same object."]},{"cell_type":"markdown","metadata":{"id":"LpLoFZqvOAzC","colab_type":"text"},"source":["The **predicted bounding box can be further fine-tuned** by another bounding box regressor."]},{"cell_type":"markdown","metadata":{"id":"taT96LK1OAzE","colab_type":"text"},"source":["### RESULTS"]},{"cell_type":"markdown","metadata":{"id":"No9LJcHCOAzF","colab_type":"text"},"source":["To **summarize**, R-CNN is just the following steps:\n","\n","1. Generate a **set of proposals** for bounding boxes.\n","\n","2. Run the i**mages in the bounding boxes** through a pre-trained **AlexNet** and finally **SVM** to see **what object the image in the box is**.\n","\n","3. Run the box through a **linear regression model** to output **tighter coordinates** for the box once the object has been classified."]},{"cell_type":"markdown","metadata":{"id":"pvClOdh-OAzH","colab_type":"text"},"source":["### Problems with R-CNN"]},{"cell_type":"markdown","metadata":{"id":"xSQJKbXWOAzJ","colab_type":"text"},"source":["- It takes a **huge amount of time** to train the network as you would have to classify **2000 region proposals per image**.\n","\n","- It **cannot be implemented** real time as it takes around 47 seconds for each test image.\n","\n","- The **selective search algorithm** is a fixed algorithm.\n","\n","- No **learning happens at that stage** which could **lead to the generation** of bad candidate region proposals."]},{"cell_type":"markdown","metadata":{"id":"HZy0ytmHOAzK","colab_type":"text"},"source":["## Fast R-CNN - Speeding up and simplifying R-CNN"]},{"cell_type":"markdown","metadata":{"id":"2OCvk7xROAzM","colab_type":"text"},"source":["R-CNN works really well, but is really **quite slow** for a few simple reasons:\n","\n","1. It requires a **forward pass of the CNN(AlexNet)** for **every single region proposal for every single image** (that's around 2000 forward passes per image).\n","\n","2. It has to train **three different models seperately** - \n","\n","    - The **CNN** to generate image features, \n","\n","    - The **classifier** that predicts the class, and \n","\n","    - The **regression model** to tighten the bounding boxes. This makes the pipeline extremely hard to train."]},{"cell_type":"markdown","metadata":{"id":"RZMNXMLJOAzO","colab_type":"text"},"source":["### Insight 1: RoI (Region of Interest) Pooling"]},{"cell_type":"markdown","metadata":{"id":"MyG_gYSUOAzP","colab_type":"text"},"source":["For the forward pass of the CNN, \"**Ross Girshick**\", the first author of R-CNN realized that for each image, a **lot of proposed regions for the image** invariably **overlapped** causing us to run the same CNN computation again and again (~2000 times). \n","\n","His insight was simple:\n","\n","- **Why not run the CNN just once per image and then find a way to share that computation across the ~2000 proposals?**"]},{"cell_type":"markdown","metadata":{"id":"EzrzLX14OAzR","colab_type":"text"},"source":["<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od10.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"OfZS4kDdOAzT","colab_type":"text"},"source":["This is exactly what Fast R-CNN does using a **technique known as RoIPool (Region of Interest Pooling)**.\n","\n","At it's core,\n","\n","- RoIPool shares the **forward pass of a CNN for an image across its subregions**.\n","\n","- In the image above, notice **how** the CNN features for each region are **obtained by selecting a corresponding region** from the CNN's features map.\n","\n","- Then, the feature in **each region are pooled** (usually using a max pooling).\n","\n","- All it takes is **one pass of the original image as opposed to ~2000**"]},{"cell_type":"markdown","metadata":{"id":"2NJ8wFW_OAzU","colab_type":"text"},"source":["### Insight 2: Combine all models into one network"]},{"cell_type":"markdown","metadata":{"id":"Ab5XEBj0OAzX","colab_type":"text"},"source":["- The earlier **insight** of Fast R-CNN is to **jointly train** the **CNN**, **classifier**, and **bounding box regressor** in a single model.\n","\n","- Earlier we had **different models** to **extract** image features (CNN), **classify**(SVM), and **tighten** bounding boxes(regressor),\n","\n","- **Fast R-CNN instead used a single network to compute all three.**"]},{"cell_type":"markdown","metadata":{"id":"tM5raq0UOAzZ","colab_type":"text"},"source":["<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od11.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"Jgz81HM8OAza","colab_type":"text"},"source":["- Fast R-CNN **replaced** the SVM classifier with a **softmax layer on top** of the CNN to **output a classififcation**.\n","\n","- There is a **linear regression layer parallel** to the softmax layer to output bounding box coordinated.\n","\n","- All the the outputs needed came from **one single network!**\n","\n","<br> \n","\n","Here are the inputs and outputs of their model:\n","\n","- **Inputs**: Images with **region proposals**.\n","\n","- **Outputs**: Object classifications of **each region along with tighter bounding boxes**.\n"]},{"cell_type":"markdown","metadata":{"id":"-bVT6ZHIOAzc","colab_type":"text"},"source":["### Why Fast R-CNN is faster than R-CNN?"]},{"cell_type":"markdown","metadata":{"id":"oLQh88KfOAze","colab_type":"text"},"source":["The reason is because we **don't have to feed 2000 region proposals to the convolutional neural network every time**.\n","\n","Instead, the convolution operation is done **only once** per image and a feature map is generated from it."]},{"cell_type":"markdown","metadata":{"id":"ZxIHvVvEOAzg","colab_type":"text"},"source":["<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od12.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"LAyaliSlOAzh","colab_type":"text"},"source":["**Inference** from the graphs:\n","\n","- We can infer that Fast R-CNN is **significantly faster**** in training and testing sessions over R-CNN.\n","\n","- Looking at the **performance** of Fast R-CNN during **testing time**, including **region proposals** **slows down** the algorithm significantly when compared to **not using region proposals**.\n","\n","- Thus, region proposals become **bottlenecks** in Fast R-CNN algorithm **affecting its performance**."]},{"cell_type":"markdown","metadata":{"id":"c3RUPflTOAzj","colab_type":"text"},"source":["### Faster R-CNN: Speeding Up Region Proposal (2016)"]},{"cell_type":"markdown","metadata":{"id":"MZoXfk1QOAzk","colab_type":"text"},"source":["Both of the above algorithms (R-CNN & Fast R-CNN) uses **selective search** to find ot the region proposals.\n","\n","- Selective search is a **slow and time consuming process** affecting the performance of the network.\n","\n","- \"Shaoqing Ren et al\" came up with an object detection algorithm that **eliminates the selective search** algorithm and lets the network learn the region proposals."]},{"cell_type":"markdown","metadata":{"id":"XRbGxJyjOAzl","colab_type":"text"},"source":["- The onsight of Faster R-CNN was that region proposals depended on features of the image that were already calculated **with the forward pass** of the CNN.\n","\n","- **So why not resuse those same CNN results for region proposals instead of running a seperated selective search algorithm?**"]},{"cell_type":"markdown","metadata":{"id":"ATkiNcgNOAzm","colab_type":"text"},"source":["<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od13.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"vHTHLr3uOAzn","colab_type":"text"},"source":["In the image above we can see how a single CNN is used to both carry out **region proposals and classification**.\n","\n","- This way **only one CNN need to be trained** and we get region proposals almost for free!\n","\n","<br> \n","\n","Here are the inputs and outputs of their model:\n","    \n","- **Inputs**: Images\n","\n","- **Outputs**: Classification and bounding box coordinates of objects in the images."]},{"cell_type":"markdown","metadata":{"id":"xH8YBdbmOAzo","colab_type":"text"},"source":["**How the regions are generated**"]},{"cell_type":"markdown","metadata":{"id":"cBNvLDyjOAzp","colab_type":"text"},"source":["Let's see how Faster R-CNN **generates these region proposals** from CNN features.\n","\n","- Faster R-CNN adds a Fully Convolutional Network on **top** of the features of the CNN creating what's known as the **Region Proposal Network**"]},{"cell_type":"markdown","metadata":{"id":"haVpfjciOAzq","colab_type":"text"},"source":["<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od14.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"ZtcIq7DEOAzr","colab_type":"text"},"source":["It works by passing a **sliding window** over the CNN feature map at **each window**, outputting **k** potential bounding boxes and scores for **how good each of those boxes** is expected to be.\n","\n","What do these **k** boxes represent?"]},{"cell_type":"markdown","metadata":{"id":"qFupVIPnOAzs","colab_type":"text"},"source":["<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od15.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"7QbpLwdZOAzt","colab_type":"text"},"source":["We know that objects in an image should **fit** certain common aspect ratios and sizes creating **k** which we call **anchor boxes**.\n","\n","For each such anchor box, we output **one bounding box and score per position in the image**.\n","\n","Let's take a look at the **inputs and outputs** to the Region Proposal Network:\n","\n","- **Inputs**: CNN Feature Map\n","\n","- **Outputs**: A bounding box per anchor. A score representing **how likely** the image in that bounding box will be an object."]},{"cell_type":"markdown","metadata":{"id":"XoN_c2EvOAzw","colab_type":"text"},"source":["We then pass each such bounding box that is likely to be an object into **Fast R-CNN to generate a classification box** which will be an object."]},{"cell_type":"markdown","metadata":{"id":"ptI4t1XJOAzw","colab_type":"text"},"source":["<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/od16.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"kHwGdnqJOAzx","colab_type":"text"},"source":["## Summary of the Algorithms covered"]},{"cell_type":"markdown","metadata":{"id":"WFfwYVAHOAzy","colab_type":"text"},"source":["| **Algorithm** | **Features** | **Prediction time/image** | **Limitations** |\n","| :-----: | :------: | :------: | :--------: |\n","| **CNN** | Divides the image into multiple regions and then classify each region into various classes | ----  | Needs a lot of regions to predict accurately and hence hihg computation time. |\n","| **R-CNN** | Uses selective search to generate regions. Extracts around 2000 regions from each image | 40-50 seconds | High computation time as each region is passed to the CNN seperately also it used three different model for making predictions. |\n","| **Fast R-CNN** | Each image is passed only once to the CNN and feature maps are extracted. Selelctive search is used on these maps to generate predictions. Combines all the three models used in R-CNN together | 2 seconds | Selective search is slow and hence computation time is still high |\n","| **Faster R-CNN** | Replaces the selective search method with region proposal network which made the algorithm much faster | 0.2 seconds | Object proposal takes time and as there are different systems working one after the other, the performance of systems depends on how the previous syste has performed. |"]}]}